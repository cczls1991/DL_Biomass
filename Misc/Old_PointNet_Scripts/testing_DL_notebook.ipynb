{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got multiple values for argument 'max_points'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\hseely\\OneDrive - UBC\\Documents\\DL_Development\\testing_DL_notebook.ipynb Cell 2'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hseely/OneDrive%20-%20UBC/Documents/DL_Development/testing_DL_notebook.ipynb#ch0000004?line=0'>1</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hseely/OneDrive%20-%20UBC/Documents/DL_Development/testing_DL_notebook.ipynb#ch0000004?line=1'>2</a>\u001b[0m \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hseely/OneDrive%20-%20UBC/Documents/DL_Development/testing_DL_notebook.ipynb#ch0000004?line=2'>3</a>\u001b[0m \u001b[39m#Import the lidar data\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/hseely/OneDrive%20-%20UBC/Documents/DL_Development/testing_DL_notebook.ipynb#ch0000004?line=4'>5</a>\u001b[0m     train_dataset \u001b[39m=\u001b[39m PointCloudsInFiles(\u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mD:\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mRomeo_Data\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hseely/OneDrive%20-%20UBC/Documents/DL_Development/testing_DL_notebook.ipynb#ch0000004?line=5'>6</a>\u001b[0m                                         \u001b[39m'\u001b[39;49m\u001b[39m*.las\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hseely/OneDrive%20-%20UBC/Documents/DL_Development/testing_DL_notebook.ipynb#ch0000004?line=6'>7</a>\u001b[0m                                         \u001b[39m'\u001b[39;49m\u001b[39mNormalizedZ\u001b[39;49m\u001b[39m'\u001b[39;49m, max_points\u001b[39m=\u001b[39;49m\u001b[39m4_000\u001b[39;49m, use_columns\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hseely/OneDrive%20-%20UBC/Documents/DL_Development/testing_DL_notebook.ipynb#ch0000004?line=10'>11</a>\u001b[0m     test_dataset \u001b[39m=\u001b[39m PointCloudsInFiles(\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39mD:\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mRomeo_Data\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hseely/OneDrive%20-%20UBC/Documents/DL_Development/testing_DL_notebook.ipynb#ch0000004?line=11'>12</a>\u001b[0m                                         \u001b[39m'\u001b[39m\u001b[39m*.las\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hseely/OneDrive%20-%20UBC/Documents/DL_Development/testing_DL_notebook.ipynb#ch0000004?line=12'>13</a>\u001b[0m                                         \u001b[39m'\u001b[39m\u001b[39mNormalizedZ\u001b[39m\u001b[39m'\u001b[39m, max_points\u001b[39m=\u001b[39m\u001b[39m4_000\u001b[39m, use_columns\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got multiple values for argument 'max_points'"
     ]
    }
   ],
   "source": [
    "#Editing Lukas dataset loader script\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import InMemoryDataset, Data\n",
    "from pathlib import Path\n",
    "import laspy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Define function to read LAS\n",
    "def read_las(pointcloudfile,get_attributes=False,useevery=1):\n",
    "    '''\n",
    "    :param pointcloudfile: specification of input file (format: las or laz)\n",
    "    :param get_attributes: if True, will return all attributes in file, otherwise will only return XYZ (default is False)\n",
    "    :param useevery: value specifies every n-th point to use from input, i.e. simple subsampling (default is 1, i.e. returning every point)\n",
    "    :return: 3D array of points (x,y,z) of length number of points in input file (or subsampled by 'useevery')\n",
    "    '''\n",
    "\n",
    "    #Read the file\n",
    "    inFile = laspy.read(pointcloudfile)\n",
    "    # get the coordinates (XYZ)\n",
    "    coords = np.vstack((inFile.x, inFile.y, inFile.z)).transpose()\n",
    "    coords = coords[::useevery, :]\n",
    "    if get_attributes == False:\n",
    "        return (coords)\n",
    "    else:\n",
    "        las_fields= [info.name for info in inFile.points.point_format.dimensions]\n",
    "        attributes = {}\n",
    "        for las_field in las_fields[3:]: # skip the X,Y,Z fields\n",
    "            attributes[las_field] = inFile.points[las_field][::useevery]\n",
    "        return (coords, attributes)\n",
    "\n",
    "\n",
    "\n",
    "files = list(Path(root_dir).glob(glob))\n",
    "max_points = 200_000\n",
    "        if use_columns is None:\n",
    "            use_columns = []\n",
    "        self.use_columns = use_columns\n",
    "        super().__init__()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        filename = str(self.files[idx])\n",
    "        coords, attrs = read_las(filename, get_attributes=True)\n",
    "        if coords.shape[0] >= self.max_points:\n",
    "            use_idx = np.random.choice(coords.shape[0], self.max_points, replace=False)\n",
    "        else:\n",
    "            use_idx = np.random.choice(coords.shape[0], self.max_points, replace=True)\n",
    "        if len(self.use_columns) > 0:\n",
    "            x = np.empty((self.max_points, len(self.use_columns)), np.float32)\n",
    "            for eix, entry in enumerate(self.use_columns):\n",
    "                x[:, eix] = attrs[entry][use_idx]\n",
    "        else:\n",
    "            x = coords[use_idx, :]\n",
    "        coords = coords - np.mean(coords, axis=0)  # centralize coordinates\n",
    "\n",
    "        #Get plot ID from filename\n",
    "        plotID = self.files[idx].basename.split(\".\")[0]\n",
    "        #Load biomass data\n",
    "        biomass_df = pd.read_csv(r\"D:\\Romeo_Data\\Outputs\\romeo_plots_w_biomass.csv\", sep = \",\", header=0)\n",
    "        #Extract total biomass value for the correct plot ID\n",
    "        total_biomass = biomass_df.loc[biomass_df[\"PlotID\"] == int(plotID)][\"total_AGB\"].values \n",
    "        \n",
    "        #Combine point cloud with biomass values\n",
    "        sample = Data(x=torch.from_numpy(x).float(),\n",
    "                      y=torch.from_numpy(total_biomass).float(),\n",
    "                      pos=torch.from_numpy(coords[use_idx, :]).float())\n",
    "        if coords.shape[0] < 100:\n",
    "            return None\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WRITING MY OWN LAS IMPORTER\n",
    "\n",
    "#Determine if every nth point will be used\n",
    "useevery = 1\n",
    "\n",
    "#List las files\n",
    "files = os.listdir(r\"D:\\Romeo_Data\\train\") #List file names in directory\n",
    "\n",
    "#Create an empty list to store las files\n",
    "las_list = []\n",
    "\n",
    "#Loop through each las to load i\n",
    "for i in len(files):\n",
    "\n",
    "    #Specify las to load\n",
    "    las_i = files[i]\n",
    "    #Read the file\n",
    "    inFile = laspy.read(r\"D:\\Romeo_Data\\train\\{}\".format(las_i))\n",
    "    # get the coordinates (XYZ)\n",
    "    coords_i = np.vstack((inFile.x, inFile.y, inFile.z)).transpose()\n",
    "    #Select every nth coord\n",
    "    coords_i = coords_i[::useevery, :]\n",
    "    #Add the plot ID (filename) to the LAS array\n",
    "    coords_i = np.append(coords_i, np.repeat(las_i.replace('.las',''), len(coords_i)), axis=0)    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9a0670d1396b53d710d8199a331178eb5bbdc5c4528bd1178d88486693d46454"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pt')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
